{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUbNLbuP8Q9IwNbvrB8Ynf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalisonAmorim/projeto_imersaoIAalura_para_avaliacao/blob/main/projeto_imersaoIAalura_para_avaliacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pDTeMw0r6c-",
        "outputId": "181000f7-d946-4bbf-fd67-4e7ea06801c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m204.8/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jjGjm6zwE7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "T1cKzkOJrUFs",
        "outputId": "4abf9521-99b9-48ca-ec15-1683aa0f4e67"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-05761af90183>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Obter a chave de API do usuário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mCHAVE_API\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobter_chave_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#insira sua api key aqui ou deixe assim para o usuário possa inserir a sua propiá\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Configurar a API do Google Generative AI com a chave de API fornecida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-05761af90183>\u001b[0m in \u001b[0;36mobter_chave_api\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mchave_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Por favor, digite sua chave de API do Google Generative AI: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchave_api\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mchave_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "\"\"\"Este script utiliza a API Google Generative AI para interagir com um modelo de linguagem grande e analisar o conteúdo de um arquivo PDF específico, permitindo que o usuário selecione o arquivo através de uma interface gráfica.\"\"\"\n",
        "\n",
        "# Importar bibliotecas necessárias\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "import PyPDF2\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Função para solicitar o o caminho do arquivo PDF\n",
        "def get_pdf_path():\n",
        "\n",
        "    file_path =  input(\"Digite o caminho para o arquivo PDF: \")\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def obter_chave_api():\n",
        "  \"\"\"Solicita ao usuário uma chave de API e a valida.\"\"\"\n",
        "\n",
        "  while True:\n",
        "    chave_api = input(\"Por favor, digite sua chave de API do Google Generative AI: \")\n",
        "    if len(chave_api) > 0:\n",
        "      return chave_api\n",
        "    else:\n",
        "      print(\"A chave de API não pode estar vazia. Tente novamente.\")\n",
        "\n",
        "# Obter a chave de API do usuário\n",
        "CHAVE_API = obter_chave_api() #insira sua api key aqui ou deixe assim para o usuário possa inserir a sua propiá\n",
        "\n",
        "# Configurar a API do Google Generative AI com a chave de API fornecida\n",
        "genai.configure(api_key=CHAVE_API)\n",
        "\n",
        "\n",
        "# Configurações para o modelo de linguagem\n",
        "generation_config = {\n",
        "    \"temperature\": 1,  # Controla a criatividade do modelo\n",
        "    \"top_p\": 0.95,     # Controla a diversidade das respostas\n",
        "    \"top_k\": 0,        # Não utilizado neste caso\n",
        "    \"max_output_tokens\": 8192  # Número máximo de tokens na resposta\n",
        "}\n",
        "\n",
        "# Configurações de segurança para o modelo\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "]\n",
        "\n",
        "# Instrução para o sistema\n",
        "system_instruction = \"Aja como um alguém que leu o arquivo e conhece com detalhes  o assunto mencione sempre a pagina e o paragrafo em que esta baseando suas respostas. Não responda nada que não esteja relacionado ao arquivo. De forma educada, diga que este assunto não esta relacionado ao livro. \"\n",
        "\n",
        "# Criar um modelo generativo com as configurações especificadas\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-pro-latest\",\n",
        "    generation_config=generation_config,\n",
        "    system_instruction=system_instruction,\n",
        "    safety_settings=safety_settings\n",
        ")\n",
        "\n",
        "# Função para extrair texto de um arquivo PDF\n",
        "def extract_pdf_pages(pathname: str) -> list[str]:\n",
        "    parts = [f\"--- START OF PDF ${pathname} ---\"]\n",
        "    with open(pathname, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            parts.append(f\"--- PAGE {page_num} ---\")\n",
        "            parts.append(text)\n",
        "    return parts\n",
        "\n",
        "# Solicitar ao usuário o caminho do arquivo PDF usando a GUI\n",
        "print(\"Escolha um arquivo PDF do seu ficheiro:\")  # Informar o usuário\n",
        "pdf_path = get_pdf_path()\n",
        "\n",
        "# Verificar se um arquivo foi selecionado\n",
        "if not pdf_path:\n",
        "    print(\"Nenhum arquivo selecionado.\")\n",
        "    exit()  # Encerrar o script se nenhum arquivo for escolhido\n",
        "\n",
        "# Iniciar uma sessão de chat com o modelo\n",
        "chat = model.start_chat(history=[])\n",
        "display(to_markdown('O que voce gostaria de saber sobre esse arquivo?'))\n",
        "\n",
        "# Solicitar ao usuário o prompt (pergunta ou instrução)\n",
        "prompt = input('Esperando prompt...')\n",
        "\n",
        "# Função para converter texto em Markdown\n",
        "def to_markdown(text):\n",
        "    text = text.replace('.', '\\n')\n",
        "    return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))\n",
        "\n",
        "# Loop para interagir com o modelo\n",
        "while prompt != \"fim\":\n",
        "    # Extrair o texto do PDF\n",
        "    pdf_text = extract_pdf_pages(pdf_path)\n",
        "\n",
        "    # Combinar o texto do PDF com o prompt\n",
        "    full_prompt = \"\\n\".join(pdf_text) + \"\\n\" + prompt\n",
        "\n",
        "    # Enviar o prompt completo para o modelo e obter a resposta\n",
        "    response = chat.send_message(full_prompt)\n",
        "\n",
        "    # Imprimir a resposta do modelo formatada com Markdown\n",
        "    display(to_markdown(f\"**Resposta assistente**: {response.text}\"))\n",
        "\n",
        "    # Solicitar o próximo prompt ou encerrar a sessão\n",
        "    prompt = input('Usuario (Digite \"fim\" para encerrar)')"
      ]
    }
  ]
}