{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEwBD1B2P4rSflkXguQIGw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalisonAmorim/projeto_imersaoIAalura_para_avaliacao/blob/main/projeto_imersaoIAalura_para_avaliacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar a biblioteca PyPDF2 no ambiente de execu√ß√£o\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "1pDTeMw0r6c-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c558b0aa-9521-4468-d67b-c200e684159b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Este script utiliza a API Google Generative AI para interagir com um modelo de linguagem grande e analisar o conte√∫do de um arquivo PDF espec√≠fico, permitindo que o usu√°rio selecione o arquivo de seu GOOGLE-DRIVER.**\n",
        "\n",
        "># CHAVE API‚ùó\n",
        " O programa solicitar√° sua Chave da API (API key) para conex√£o com os servi√ßos da Gemini da Google. Para acessar sua chave API, clique no seguinte link: http://bit.ly/49NYCHv. üîë\n",
        "\n"
      ],
      "metadata": {
        "id": "x_R-SFVMcPpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T1cKzkOJrUFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "b4ddcadd-fdc0-4d2a-8c42-6cae1fbec95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, digite sua chave de API do Google Generative AI: AIzaSyBnDc7fI7NbPqIIzJGfOv3i7DTVoIjaa3o\n",
            "Escolha um arquivo PDF do seu ficheiro:\n",
            "Digite o caminho para o arquivo PDF: /content/revis√£o prova pos layane.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">O que voce gostaria de saber sobre esse arquivo?"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt...fim\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Importar bibliotecas necess√°rias\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "import PyPDF2\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Fun√ß√£o para solicitar o o caminho do arquivo PDF\n",
        "def get_pdf_path():\n",
        "\n",
        "    file_path =  input(\"Digite o caminho para o arquivo PDF: \")\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def obter_chave_api():\n",
        "  \"\"\"Solicita ao usu√°rio uma chave de API e a valida.\"\"\"\n",
        "\n",
        "  while True:\n",
        "    chave_api = input(\"Por favor, digite sua chave de API do Google Generative AI: \")\n",
        "    if len(chave_api) > 0:\n",
        "      return chave_api\n",
        "    else:\n",
        "      print(\"A chave de API n√£o pode estar vazia. Tente novamente.\")\n",
        "\n",
        "# Obter a chave de API do usu√°rio\n",
        "CHAVE_API = obter_chave_api() #insira sua api key aqui ou deixe assim para o usu√°rio possa inserir a sua propi√°\n",
        "\n",
        "# Configurar a API do Google Generative AI com a chave de API fornecida\n",
        "genai.configure(api_key=CHAVE_API)\n",
        "\n",
        "\n",
        "# Configura√ß√µes para o modelo de linguagem\n",
        "generation_config = {\n",
        "    \"temperature\": 1,  # Controla a criatividade do modelo\n",
        "    \"top_p\": 0.95,     # Controla a diversidade das respostas\n",
        "    \"top_k\": 0,        # N√£o utilizado neste caso\n",
        "    \"max_output_tokens\": 8192  # N√∫mero m√°ximo de tokens na resposta\n",
        "}\n",
        "\n",
        "# Configura√ß√µes de seguran√ßa para o modelo\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "]\n",
        "\n",
        "# Instru√ß√£o para o sistema\n",
        "system_instruction = \"Aja como um algu√©m que leu o arquivo e conhece com detalhes  o assunto mencione sempre a pagina e o paragrafo em que esta baseando suas respostas. N√£o responda nada que n√£o esteja relacionado ao arquivo. De forma educada, diga que este assunto n√£o esta relacionado ao livro. \"\n",
        "\n",
        "# Criar um modelo generativo com as configura√ß√µes especificadas\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-pro-latest\",\n",
        "    generation_config=generation_config,\n",
        "    system_instruction=system_instruction,\n",
        "    safety_settings=safety_settings\n",
        ")\n",
        "\n",
        "# Fun√ß√£o para extrair texto de um arquivo PDF\n",
        "def extract_pdf_pages(pathname: str) -> list[str]:\n",
        "    parts = [f\"--- START OF PDF ${pathname} ---\"]\n",
        "    with open(pathname, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            parts.append(f\"--- PAGE {page_num} ---\")\n",
        "            parts.append(text)\n",
        "    return parts\n",
        "\n",
        "# Solicitar ao usu√°rio o caminho do arquivo PDF usando a GUI\n",
        "print(\"Escolha um arquivo PDF do seu ficheiro:\")  # Informar o usu√°rio\n",
        "pdf_path = get_pdf_path()\n",
        "\n",
        "# Verificar se um arquivo foi selecionado\n",
        "if not pdf_path:\n",
        "    print(\"Nenhum arquivo selecionado.\")\n",
        "    exit()  # Encerrar o script se nenhum arquivo for escolhido\n",
        "\n",
        "    # Fun√ß√£o para converter texto em Markdown\n",
        "def to_markdown(text):\n",
        "    text = text.replace('.', '\\n')\n",
        "    return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))\n",
        "\n",
        "# Iniciar uma sess√£o de chat com o modelo\n",
        "chat = model.start_chat(history=[])\n",
        "display(to_markdown('O que voce gostaria de saber sobre esse arquivo?'))\n",
        "\n",
        "# Solicitar ao usu√°rio o prompt (pergunta ou instru√ß√£o)\n",
        "prompt = input('Esperando prompt...')\n",
        "\n",
        "# Loop para interagir com o modelo\n",
        "while prompt != \"fim\":\n",
        "    # Extrair o texto do PDF\n",
        "    pdf_text = extract_pdf_pages(pdf_path)\n",
        "\n",
        "    # Combinar o texto do PDF com o prompt\n",
        "    full_prompt = \"\\n\".join(pdf_text) + \"\\n\" + prompt\n",
        "\n",
        "    # Enviar o prompt completo para o modelo e obter a resposta\n",
        "    response = chat.send_message(full_prompt)\n",
        "\n",
        "    # Imprimir a resposta do modelo formatada com Markdown\n",
        "    display(to_markdown(f\"**Resposta assistente**: {response.text}\"))\n",
        "\n",
        "    # Solicitar o pr√≥ximo prompt ou encerrar a sess√£o\n",
        "    prompt = input('Usuario (Digite \"fim\" para encerrar)')"
      ]
    }
  ]
}