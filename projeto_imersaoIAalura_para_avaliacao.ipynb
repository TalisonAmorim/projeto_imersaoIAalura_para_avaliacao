{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIYLdGsfjZuBLQIqnGsFV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalisonAmorim/projeto_imersaoIAalura_para_avaliacao/blob/main/projeto_imersaoIAalura_para_avaliacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "1pDTeMw0r6c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1cKzkOJrUFs"
      },
      "outputs": [],
      "source": [
        "\"\"\"Este script utiliza a API Google Generative AI para interagir com um modelo de linguagem grande e analisar o conteúdo de um arquivo PDF específico, permitindo que o usuário selecione o arquivo através de uma interface gráfica.\"\"\"\n",
        "\n",
        "# Importar bibliotecas necessárias\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "import PyPDF2\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Função para solicitar o o caminho do arquivo PDF\n",
        "def get_pdf_path():\n",
        "\n",
        "    file_path =  input(\"Digite o caminho para o arquivo PDF: \")\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def obter_chave_api():\n",
        "  \"\"\"Solicita ao usuário uma chave de API e a valida.\"\"\"\n",
        "\n",
        "  while True:\n",
        "    chave_api = input(\"Por favor, digite sua chave de API do Google Generative AI: \")\n",
        "    if len(chave_api) > 0:\n",
        "      return chave_api\n",
        "    else:\n",
        "      print(\"A chave de API não pode estar vazia. Tente novamente.\")\n",
        "\n",
        "# Obter a chave de API do usuário\n",
        "CHAVE_API = obter_chave_api() #insira sua api key aqui ou deixe assim para o usuário possa inserir a sua propiá\n",
        "\n",
        "# Configurar a API do Google Generative AI com a chave de API fornecida\n",
        "genai.configure(api_key=CHAVE_API)\n",
        "\n",
        "\n",
        "# Configurações para o modelo de linguagem\n",
        "generation_config = {\n",
        "    \"temperature\": 1,  # Controla a criatividade do modelo\n",
        "    \"top_p\": 0.95,     # Controla a diversidade das respostas\n",
        "    \"top_k\": 0,        # Não utilizado neste caso\n",
        "    \"max_output_tokens\": 8192  # Número máximo de tokens na resposta\n",
        "}\n",
        "\n",
        "# Configurações de segurança para o modelo\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "]\n",
        "\n",
        "# Instrução para o sistema\n",
        "system_instruction = \"Aja como um alguém que leu o arquivo e conhece com detalhes  o assunto mencione sempre a pagina e o paragrafo em que esta baseando suas respostas. Não responda nada que não esteja relacionado ao arquivo. De forma educada, diga que este assunto não esta relacionado ao livro. \"\n",
        "\n",
        "# Criar um modelo generativo com as configurações especificadas\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-pro-latest\",\n",
        "    generation_config=generation_config,\n",
        "    system_instruction=system_instruction,\n",
        "    safety_settings=safety_settings\n",
        ")\n",
        "\n",
        "# Função para extrair texto de um arquivo PDF\n",
        "def extract_pdf_pages(pathname: str) -> list[str]:\n",
        "    parts = [f\"--- START OF PDF ${pathname} ---\"]\n",
        "    with open(pathname, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            parts.append(f\"--- PAGE {page_num} ---\")\n",
        "            parts.append(text)\n",
        "    return parts\n",
        "\n",
        "# Solicitar ao usuário o caminho do arquivo PDF usando a GUI\n",
        "print(\"Escolha um arquivo PDF do seu ficheiro:\")  # Informar o usuário\n",
        "pdf_path = get_pdf_path()\n",
        "\n",
        "# Verificar se um arquivo foi selecionado\n",
        "if not pdf_path:\n",
        "    print(\"Nenhum arquivo selecionado.\")\n",
        "    exit()  # Encerrar o script se nenhum arquivo for escolhido\n",
        "\n",
        "# Iniciar uma sessão de chat com o modelo\n",
        "chat = model.start_chat(history=[])\n",
        "display(to_markdown('O que voce gostaria de saber sobre esse arquivo?'))\n",
        "\n",
        "# Solicitar ao usuário o prompt (pergunta ou instrução)\n",
        "prompt = input('Esperando prompt...')\n",
        "\n",
        "# Função para converter texto em Markdown\n",
        "def to_markdown(text):\n",
        "    text = text.replace('.', '\\n')\n",
        "    return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))\n",
        "\n",
        "# Loop para interagir com o modelo\n",
        "while prompt != \"fim\":\n",
        "    # Extrair o texto do PDF\n",
        "    pdf_text = extract_pdf_pages(pdf_path)\n",
        "\n",
        "    # Combinar o texto do PDF com o prompt\n",
        "    full_prompt = \"\\n\".join(pdf_text) + \"\\n\" + prompt\n",
        "\n",
        "    # Enviar o prompt completo para o modelo e obter a resposta\n",
        "    response = chat.send_message(full_prompt)\n",
        "\n",
        "    # Imprimir a resposta do modelo formatada com Markdown\n",
        "    display(to_markdown(f\"**Resposta assistente**: {response.text}\"))\n",
        "\n",
        "    # Solicitar o próximo prompt ou encerrar a sessão\n",
        "    prompt = input('Usuario (Digite \"fim\" para encerrar)')"
      ]
    }
  ]
}